import streamlit as st
from speechbrain.pretrained import Tacotron2, HIFIGAN
import torchaudio
import torch
import io
import time

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
@st.cache_resource
def load_models():
    tts = Tacotron2.from_hparams(source="speechbrain/tts-tacotron2-ljspeech")
    vocoder = HIFIGAN.from_hparams(source="speechbrain/tts-hifigan-ljspeech")
    return tts, vocoder

tts, vocoder = load_models()

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.title("ğŸ—£ï¸ Text-to-Speech (SpeechBrain)")
text = st.text_area("ğŸ’¬ Ø£Ø¯Ø®Ù„ Ù†ØµÙ‹Ø§ Ù„ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ ØµÙˆØª:", "This is a test using SpeechBrain and Streamlit.")

# Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
speed = st.slider("âš¡ Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ´ØºÙŠÙ„", 0.5, 2.0, 1.0, 0.1)

# Ø¯Ø§Ù„Ø© Ù„ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ ØµØºÙŠØ±Ø©
def split_text(text, max_words=100):
    words = text.split()
    return [' '.join(words[i:i+max_words]) for i in range(0, len(words), max_words)]

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª
def text_to_speech(text, speed):
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡
    text_parts = split_text(text)
    audio_parts = []
    
    for part in text_parts:
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…ÙŠÙ„ Ø³Ø¨ÙŠÙƒØªØ±Ø¬Ø±Ø§Ù…
        mel_output, mel_length, alignment = tts.encode_text(part)

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙŠÙ„ Ø¥Ù„Ù‰ ØµÙˆØª
        waveform = vocoder.decode_batch(mel_output)

        # ØªØ·Ø¨ÙŠÙ‚ ØªØºÙŠÙŠØ± Ø§Ù„Ø³Ø±Ø¹Ø©
        new_sample_rate = int(22050 * speed)

        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØª ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
        buffer = io.BytesIO()
        torchaudio.save(buffer, waveform.squeeze(1), new_sample_rate, format="wav")
        buffer.seek(0)
        audio_parts.append(buffer)
    
    return audio_parts

if st.button("ğŸ§ Ø§Ø³ØªÙ…Ø¹"):
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­ÙˆÙŠÙ„..."):
        start_time = time.time()
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª
        audio_parts = text_to_speech(text, speed)
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØµÙˆØªÙŠØ©
        combined_audio = io.BytesIO()
        for part in audio_parts:
            combined_audio.write(part.read())
        
        combined_audio.seek(0)
        end_time = time.time()
        
        st.audio(combined_audio, format="audio/wav")
        st.write(f"â±ï¸ ØªÙ… Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙÙŠ {end_time - start_time:.2f} Ø«Ø§Ù†ÙŠØ©")
