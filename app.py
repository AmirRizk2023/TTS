import streamlit as st
from speechbrain.pretrained import Tacotron2, HIFIGAN
import torchaudio
import torch
import io
import math

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
@st.cache_resource
def load_models():
    tts = Tacotron2.from_hparams(source="speechbrain/tts-tacotron2-ljspeech")
    vocoder = HIFIGAN.from_hparams(source="speechbrain/tts-hifigan-ljspeech")
    return tts, vocoder

tts, vocoder = load_models()

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ Ø£ÙƒØ¨Ø± (150 ÙƒÙ„Ù…Ø©)
def split_text(text, max_words=150):
    words = text.split()
    return [' '.join(words[i:i+max_words]) for i in range(0, len(words), max_words)]

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.title("ğŸ—£ï¸ Text-to-Speech (SpeechBrain)")
text = st.text_area("ğŸ’¬ Ø£Ø¯Ø®Ù„ Ù†ØµÙ‹Ø§ Ù„ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ ØµÙˆØª:", "This is a test using SpeechBrain and Streamlit.")

speed = st.slider("âš¡ Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ´ØºÙŠÙ„", 0.5, 2.0, 1.0, 0.1)

if st.button("ğŸ§ Ø§Ø³ØªÙ…Ø¹"):
    with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­ÙˆÙŠÙ„..."):
        segments = split_text(text, max_words=150)
        final_waveform = []

        for segment in segments:
            mel_output, mel_length, alignment = tts.encode_text(segment)
            waveform = vocoder.decode_batch(mel_output)
            final_waveform.append(waveform.squeeze(1))

        # Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ØµÙˆØªÙŠØ© ÙÙŠ Ù…ÙˆØ¬Ø© ÙˆØ§Ø­Ø¯Ø©
        combined_waveform = torch.cat(final_waveform, dim=1)

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        new_sample_rate = int(22050 * speed)
        buffer = io.BytesIO()
        torchaudio.save(buffer, combined_waveform, new_sample_rate, format="wav")
        buffer.seek(0)

        st.audio(buffer, format="audio/wav")
